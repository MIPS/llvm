; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv32 -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV32I
; RUN: llc -mtriple=riscv32 -target-abi ilp32d -mattr=+d -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV32D
; RUN: llc -mtriple=riscv64 -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV64I
; RUN: llc -mtriple=riscv64 -target-abi lp64d -mattr=+d -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV64D
; RUN: llc -mtriple=riscv32 -mattr=+load-store-pairs -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV32I_PAIR
; RUN: llc -mtriple=riscv32 -target-abi ilp32d -mattr=+d,+load-store-pairs -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV32D_PAIR
; RUN: llc -mtriple=riscv64 -mattr=+load-store-pairs -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV64I_PAIR
; RUN: llc -mtriple=riscv64 -mcpu i8500 -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV64I_8500
; RUN: llc -mtriple=riscv64 -target-abi lp64d -mattr=+d,+load-store-pairs -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV64D_PAIR
; RUN: llc -mtriple=riscv64 -target-abi lp64d -mattr=+d -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=RV64D_8500

define dso_local void @testi(i8** nocapture noundef readonly %a) local_unnamed_addr #0 {
; RV32I-LABEL: testi:
; RV32I:       # %bb.0: # %entry
; RV32I-NEXT:    addi sp, sp, -16
; RV32I-NEXT:    .cfi_def_cfa_offset 16
; RV32I-NEXT:    sw s2, 12(sp) # 4-byte Folded Spill
; RV32I-NEXT:    sw s3, 8(sp) # 4-byte Folded Spill
; RV32I-NEXT:    sw s4, 4(sp) # 4-byte Folded Spill
; RV32I-NEXT:    sw s5, 0(sp) # 4-byte Folded Spill
; RV32I-NEXT:    .cfi_offset s2, -4
; RV32I-NEXT:    .cfi_offset s3, -8
; RV32I-NEXT:    .cfi_offset s4, -12
; RV32I-NEXT:    .cfi_offset s5, -16
; RV32I-NEXT:    lw s2, 4(a0)
; RV32I-NEXT:    lw s3, 0(a0)
; RV32I-NEXT:    lw s4, 12(a0)
; RV32I-NEXT:    lw s5, 8(a0)
; RV32I-NEXT:    #APP
; RV32I-NEXT:    #NO_APP
; RV32I-NEXT:    lw s2, 12(sp) # 4-byte Folded Reload
; RV32I-NEXT:    lw s3, 8(sp) # 4-byte Folded Reload
; RV32I-NEXT:    lw s4, 4(sp) # 4-byte Folded Reload
; RV32I-NEXT:    lw s5, 0(sp) # 4-byte Folded Reload
; RV32I-NEXT:    addi sp, sp, 16
; RV32I-NEXT:    ret
;
; RV32D-LABEL: testi:
; RV32D:       # %bb.0: # %entry
; RV32D-NEXT:    addi sp, sp, -16
; RV32D-NEXT:    .cfi_def_cfa_offset 16
; RV32D-NEXT:    sw s2, 12(sp) # 4-byte Folded Spill
; RV32D-NEXT:    sw s3, 8(sp) # 4-byte Folded Spill
; RV32D-NEXT:    sw s4, 4(sp) # 4-byte Folded Spill
; RV32D-NEXT:    sw s5, 0(sp) # 4-byte Folded Spill
; RV32D-NEXT:    .cfi_offset s2, -4
; RV32D-NEXT:    .cfi_offset s3, -8
; RV32D-NEXT:    .cfi_offset s4, -12
; RV32D-NEXT:    .cfi_offset s5, -16
; RV32D-NEXT:    lw s2, 4(a0)
; RV32D-NEXT:    lw s3, 0(a0)
; RV32D-NEXT:    lw s4, 12(a0)
; RV32D-NEXT:    lw s5, 8(a0)
; RV32D-NEXT:    #APP
; RV32D-NEXT:    #NO_APP
; RV32D-NEXT:    lw s2, 12(sp) # 4-byte Folded Reload
; RV32D-NEXT:    lw s3, 8(sp) # 4-byte Folded Reload
; RV32D-NEXT:    lw s4, 4(sp) # 4-byte Folded Reload
; RV32D-NEXT:    lw s5, 0(sp) # 4-byte Folded Reload
; RV32D-NEXT:    addi sp, sp, 16
; RV32D-NEXT:    ret
;
; RV64I-LABEL: testi:
; RV64I:       # %bb.0: # %entry
; RV64I-NEXT:    addi sp, sp, -32
; RV64I-NEXT:    .cfi_def_cfa_offset 32
; RV64I-NEXT:    sd s2, 24(sp) # 8-byte Folded Spill
; RV64I-NEXT:    sd s3, 16(sp) # 8-byte Folded Spill
; RV64I-NEXT:    sd s4, 8(sp) # 8-byte Folded Spill
; RV64I-NEXT:    sd s5, 0(sp) # 8-byte Folded Spill
; RV64I-NEXT:    .cfi_offset s2, -8
; RV64I-NEXT:    .cfi_offset s3, -16
; RV64I-NEXT:    .cfi_offset s4, -24
; RV64I-NEXT:    .cfi_offset s5, -32
; RV64I-NEXT:    ld s2, 8(a0)
; RV64I-NEXT:    ld s3, 0(a0)
; RV64I-NEXT:    ld s4, 24(a0)
; RV64I-NEXT:    ld s5, 16(a0)
; RV64I-NEXT:    #APP
; RV64I-NEXT:    #NO_APP
; RV64I-NEXT:    ld s2, 24(sp) # 8-byte Folded Reload
; RV64I-NEXT:    ld s3, 16(sp) # 8-byte Folded Reload
; RV64I-NEXT:    ld s4, 8(sp) # 8-byte Folded Reload
; RV64I-NEXT:    ld s5, 0(sp) # 8-byte Folded Reload
; RV64I-NEXT:    addi sp, sp, 32
; RV64I-NEXT:    ret
;
; RV64D-LABEL: testi:
; RV64D:       # %bb.0: # %entry
; RV64D-NEXT:    addi sp, sp, -32
; RV64D-NEXT:    .cfi_def_cfa_offset 32
; RV64D-NEXT:    sd s2, 24(sp) # 8-byte Folded Spill
; RV64D-NEXT:    sd s3, 16(sp) # 8-byte Folded Spill
; RV64D-NEXT:    sd s4, 8(sp) # 8-byte Folded Spill
; RV64D-NEXT:    sd s5, 0(sp) # 8-byte Folded Spill
; RV64D-NEXT:    .cfi_offset s2, -8
; RV64D-NEXT:    .cfi_offset s3, -16
; RV64D-NEXT:    .cfi_offset s4, -24
; RV64D-NEXT:    .cfi_offset s5, -32
; RV64D-NEXT:    ld s2, 8(a0)
; RV64D-NEXT:    ld s3, 0(a0)
; RV64D-NEXT:    ld s4, 24(a0)
; RV64D-NEXT:    ld s5, 16(a0)
; RV64D-NEXT:    #APP
; RV64D-NEXT:    #NO_APP
; RV64D-NEXT:    ld s2, 24(sp) # 8-byte Folded Reload
; RV64D-NEXT:    ld s3, 16(sp) # 8-byte Folded Reload
; RV64D-NEXT:    ld s4, 8(sp) # 8-byte Folded Reload
; RV64D-NEXT:    ld s5, 0(sp) # 8-byte Folded Reload
; RV64D-NEXT:    addi sp, sp, 32
; RV64D-NEXT:    ret
;
; RV32I_PAIR-LABEL: testi:
; RV32I_PAIR:       # %bb.0: # %entry
; RV32I_PAIR-NEXT:    addi sp, sp, -16
; RV32I_PAIR-NEXT:    .cfi_def_cfa_offset 16
; RV32I_PAIR-NEXT:    swp s3, s2, 8(sp) # 8-byte Folded Spill
; RV32I_PAIR-NEXT:    swp s5, s4, 0(sp) # 8-byte Folded Spill
; RV32I_PAIR-NEXT:    .cfi_offset s2, -4
; RV32I_PAIR-NEXT:    .cfi_offset s3, -8
; RV32I_PAIR-NEXT:    .cfi_offset s4, -12
; RV32I_PAIR-NEXT:    .cfi_offset s5, -16
; RV32I_PAIR-NEXT:    lwp s3, s2, 0(a0)
; RV32I_PAIR-NEXT:    lwp s5, s4, 8(a0)
; RV32I_PAIR-NEXT:    #APP
; RV32I_PAIR-NEXT:    #NO_APP
; RV32I_PAIR-NEXT:    lwp s3, s2, 8(sp) # 8-byte Folded Reload
; RV32I_PAIR-NEXT:    lwp s5, s4, 0(sp) # 8-byte Folded Reload
; RV32I_PAIR-NEXT:    addi sp, sp, 16
; RV32I_PAIR-NEXT:    ret
;
; RV32D_PAIR-LABEL: testi:
; RV32D_PAIR:       # %bb.0: # %entry
; RV32D_PAIR-NEXT:    addi sp, sp, -16
; RV32D_PAIR-NEXT:    .cfi_def_cfa_offset 16
; RV32D_PAIR-NEXT:    swp s3, s2, 8(sp) # 8-byte Folded Spill
; RV32D_PAIR-NEXT:    swp s5, s4, 0(sp) # 8-byte Folded Spill
; RV32D_PAIR-NEXT:    .cfi_offset s2, -4
; RV32D_PAIR-NEXT:    .cfi_offset s3, -8
; RV32D_PAIR-NEXT:    .cfi_offset s4, -12
; RV32D_PAIR-NEXT:    .cfi_offset s5, -16
; RV32D_PAIR-NEXT:    lwp s3, s2, 0(a0)
; RV32D_PAIR-NEXT:    lwp s5, s4, 8(a0)
; RV32D_PAIR-NEXT:    #APP
; RV32D_PAIR-NEXT:    #NO_APP
; RV32D_PAIR-NEXT:    lwp s3, s2, 8(sp) # 8-byte Folded Reload
; RV32D_PAIR-NEXT:    lwp s5, s4, 0(sp) # 8-byte Folded Reload
; RV32D_PAIR-NEXT:    addi sp, sp, 16
; RV32D_PAIR-NEXT:    ret
;
; RV64I_PAIR-LABEL: testi:
; RV64I_PAIR:       # %bb.0: # %entry
; RV64I_PAIR-NEXT:    addi sp, sp, -32
; RV64I_PAIR-NEXT:    .cfi_def_cfa_offset 32
; RV64I_PAIR-NEXT:    sdp s3, s2, 16(sp) # 16-byte Folded Spill
; RV64I_PAIR-NEXT:    sdp s5, s4, 0(sp) # 16-byte Folded Spill
; RV64I_PAIR-NEXT:    .cfi_offset s2, -8
; RV64I_PAIR-NEXT:    .cfi_offset s3, -16
; RV64I_PAIR-NEXT:    .cfi_offset s4, -24
; RV64I_PAIR-NEXT:    .cfi_offset s5, -32
; RV64I_PAIR-NEXT:    ld s3, 0(a0)
; RV64I_PAIR-NEXT:    ld s2, 8(a0)
; RV64I_PAIR-NEXT:    ld s5, 16(a0)
; RV64I_PAIR-NEXT:    ld s4, 24(a0)
; RV64I_PAIR-NEXT:    #APP
; RV64I_PAIR-NEXT:    #NO_APP
; RV64I_PAIR-NEXT:    ldp s3, s2, 16(sp) # 16-byte Folded Reload
; RV64I_PAIR-NEXT:    ldp s5, s4, 0(sp) # 16-byte Folded Reload
; RV64I_PAIR-NEXT:    addi sp, sp, 32
; RV64I_PAIR-NEXT:    ret
;
; RV64I_8500-LABEL: testi:
; RV64I_8500:       # %bb.0: # %entry
; RV64I_8500-NEXT:    addi sp, sp, -32
; RV64I_8500-NEXT:    .cfi_def_cfa_offset 32
; RV64I_8500-NEXT:    sdp s3, s2, 16(sp) # 16-byte Folded Spill
; RV64I_8500-NEXT:    sdp s5, s4, 0(sp) # 16-byte Folded Spill
; RV64I_8500-NEXT:    .cfi_offset s2, -8
; RV64I_8500-NEXT:    .cfi_offset s3, -16
; RV64I_8500-NEXT:    .cfi_offset s4, -24
; RV64I_8500-NEXT:    .cfi_offset s5, -32
; RV64I_8500-NEXT:    ld s3, 0(a0)
; RV64I_8500-NEXT:    ld s2, 8(a0)
; RV64I_8500-NEXT:    ld s5, 16(a0)
; RV64I_8500-NEXT:    ld s4, 24(a0)
; RV64I_8500-NEXT:    #APP
; RV64I_8500-NEXT:    #NO_APP
; RV64I_8500-NEXT:    ldp s3, s2, 16(sp) # 16-byte Folded Reload
; RV64I_8500-NEXT:    ldp s5, s4, 0(sp) # 16-byte Folded Reload
; RV64I_8500-NEXT:    addi sp, sp, 32
; RV64I_8500-NEXT:    ret
;
; RV64D_PAIR-LABEL: testi:
; RV64D_PAIR:       # %bb.0: # %entry
; RV64D_PAIR-NEXT:    addi sp, sp, -32
; RV64D_PAIR-NEXT:    .cfi_def_cfa_offset 32
; RV64D_PAIR-NEXT:    sdp s3, s2, 16(sp) # 16-byte Folded Spill
; RV64D_PAIR-NEXT:    sdp s5, s4, 0(sp) # 16-byte Folded Spill
; RV64D_PAIR-NEXT:    .cfi_offset s2, -8
; RV64D_PAIR-NEXT:    .cfi_offset s3, -16
; RV64D_PAIR-NEXT:    .cfi_offset s4, -24
; RV64D_PAIR-NEXT:    .cfi_offset s5, -32
; RV64D_PAIR-NEXT:    ld s3, 0(a0)
; RV64D_PAIR-NEXT:    ld s2, 8(a0)
; RV64D_PAIR-NEXT:    ld s5, 16(a0)
; RV64D_PAIR-NEXT:    ld s4, 24(a0)
; RV64D_PAIR-NEXT:    #APP
; RV64D_PAIR-NEXT:    #NO_APP
; RV64D_PAIR-NEXT:    ldp s3, s2, 16(sp) # 16-byte Folded Reload
; RV64D_PAIR-NEXT:    ldp s5, s4, 0(sp) # 16-byte Folded Reload
; RV64D_PAIR-NEXT:    addi sp, sp, 32
; RV64D_PAIR-NEXT:    ret
;
; RV64D_8500-LABEL: testi:
; RV64D_8500:       # %bb.0: # %entry
; RV64D_8500-NEXT:    addi sp, sp, -32
; RV64D_8500-NEXT:    .cfi_def_cfa_offset 32
; RV64D_8500-NEXT:    sd s2, 24(sp) # 8-byte Folded Spill
; RV64D_8500-NEXT:    sd s3, 16(sp) # 8-byte Folded Spill
; RV64D_8500-NEXT:    sd s4, 8(sp) # 8-byte Folded Spill
; RV64D_8500-NEXT:    sd s5, 0(sp) # 8-byte Folded Spill
; RV64D_8500-NEXT:    .cfi_offset s2, -8
; RV64D_8500-NEXT:    .cfi_offset s3, -16
; RV64D_8500-NEXT:    .cfi_offset s4, -24
; RV64D_8500-NEXT:    .cfi_offset s5, -32
; RV64D_8500-NEXT:    ld s2, 8(a0)
; RV64D_8500-NEXT:    ld s3, 0(a0)
; RV64D_8500-NEXT:    ld s4, 24(a0)
; RV64D_8500-NEXT:    ld s5, 16(a0)
; RV64D_8500-NEXT:    #APP
; RV64D_8500-NEXT:    #NO_APP
; RV64D_8500-NEXT:    ld s2, 24(sp) # 8-byte Folded Reload
; RV64D_8500-NEXT:    ld s3, 16(sp) # 8-byte Folded Reload
; RV64D_8500-NEXT:    ld s4, 8(sp) # 8-byte Folded Reload
; RV64D_8500-NEXT:    ld s5, 0(sp) # 8-byte Folded Reload
; RV64D_8500-NEXT:    addi sp, sp, 32
; RV64D_8500-NEXT:    ret
entry:
  %arrayidx = getelementptr inbounds i8*, i8** %a, i64 1
  %0 = load i8*, i8** %arrayidx, align 8
  %1 = load i8*, i8** %a, align 8
  %arrayidx2 = getelementptr inbounds i8*, i8** %a, i64 3
  %2 = load i8*, i8** %arrayidx2, align 8
  %arrayidx3 = getelementptr inbounds i8*, i8** %a, i64 2
  %3 = load i8*, i8** %arrayidx3, align 8
  tail call void asm sideeffect "", "{x18},{x19},{x20},{x21}"(i8* %0, i8* %1, i8* %2, i8* %3)
  ret void
}


define dso_local void @testf(float* nocapture noundef readonly %a) local_unnamed_addr #0 {
; RV32I-LABEL: testf:
; RV32I:       # %bb.0: # %entry
; RV32I-NEXT:    lw a3, 0(a0)
; RV32I-NEXT:    lw a2, 8(a0)
; RV32I-NEXT:    lw a1, 12(a0)
; RV32I-NEXT:    lw a0, 4(a0)
; RV32I-NEXT:    tail sinkf
;
; RV32D-LABEL: testf:
; RV32D:       # %bb.0: # %entry
; RV32D-NEXT:    flw fa0, 4(a0)
; RV32D-NEXT:    flw fa1, 12(a0)
; RV32D-NEXT:    flw fa2, 8(a0)
; RV32D-NEXT:    flw fa3, 0(a0)
; RV32D-NEXT:    tail sinkf
;
; RV64I-LABEL: testf:
; RV64I:       # %bb.0: # %entry
; RV64I-NEXT:    lw a3, 0(a0)
; RV64I-NEXT:    lw a2, 8(a0)
; RV64I-NEXT:    lw a1, 12(a0)
; RV64I-NEXT:    lw a0, 4(a0)
; RV64I-NEXT:    tail sinkf
;
; RV64D-LABEL: testf:
; RV64D:       # %bb.0: # %entry
; RV64D-NEXT:    flw fa0, 4(a0)
; RV64D-NEXT:    flw fa1, 12(a0)
; RV64D-NEXT:    flw fa2, 8(a0)
; RV64D-NEXT:    flw fa3, 0(a0)
; RV64D-NEXT:    tail sinkf
;
; RV32I_PAIR-LABEL: testf:
; RV32I_PAIR:       # %bb.0: # %entry
; RV32I_PAIR-NEXT:    lw a3, 0(a0)
; RV32I_PAIR-NEXT:    lw a2, 8(a0)
; RV32I_PAIR-NEXT:    lw a1, 12(a0)
; RV32I_PAIR-NEXT:    lw a0, 4(a0)
; RV32I_PAIR-NEXT:    tail sinkf
;
; RV32D_PAIR-LABEL: testf:
; RV32D_PAIR:       # %bb.0: # %entry
; RV32D_PAIR-NEXT:    flw fa0, 4(a0)
; RV32D_PAIR-NEXT:    flw fa2, 8(a0)
; RV32D_PAIR-NEXT:    flw fa1, 12(a0)
; RV32D_PAIR-NEXT:    flw fa3, 0(a0)
; RV32D_PAIR-NEXT:    tail sinkf
;
; RV64I_PAIR-LABEL: testf:
; RV64I_PAIR:       # %bb.0: # %entry
; RV64I_PAIR-NEXT:    lw a3, 0(a0)
; RV64I_PAIR-NEXT:    lw a2, 8(a0)
; RV64I_PAIR-NEXT:    lw a1, 12(a0)
; RV64I_PAIR-NEXT:    lw a0, 4(a0)
; RV64I_PAIR-NEXT:    tail sinkf
;
; RV64I_8500-LABEL: testf:
; RV64I_8500:       # %bb.0: # %entry
; RV64I_8500-NEXT:    flw fa0, 4(a0)
; RV64I_8500-NEXT:    flw fa2, 8(a0)
; RV64I_8500-NEXT:    flw fa1, 12(a0)
; RV64I_8500-NEXT:    flw fa3, 0(a0)
; RV64I_8500-NEXT:    tail sinkf
;
; RV64D_PAIR-LABEL: testf:
; RV64D_PAIR:       # %bb.0: # %entry
; RV64D_PAIR-NEXT:    flw fa0, 4(a0)
; RV64D_PAIR-NEXT:    flw fa2, 8(a0)
; RV64D_PAIR-NEXT:    flw fa1, 12(a0)
; RV64D_PAIR-NEXT:    flw fa3, 0(a0)
; RV64D_PAIR-NEXT:    tail sinkf
;
; RV64D_8500-LABEL: testf:
; RV64D_8500:       # %bb.0: # %entry
; RV64D_8500-NEXT:    flw fa0, 4(a0)
; RV64D_8500-NEXT:    flw fa1, 12(a0)
; RV64D_8500-NEXT:    flw fa2, 8(a0)
; RV64D_8500-NEXT:    flw fa3, 0(a0)
; RV64D_8500-NEXT:    tail sinkf
entry:
  %arrayidx = getelementptr inbounds float, float* %a, i64 1
  %0 = load float, float* %arrayidx, align 4
  %arrayidx1 = getelementptr inbounds float, float* %a, i64 3
  %1 = load float, float* %arrayidx1, align 4
  %arrayidx2 = getelementptr inbounds float, float* %a, i64 2
  %2 = load float, float* %arrayidx2, align 4
  %3 = load float, float* %a, align 4
  tail call void @sinkf(float noundef %0, float noundef %1, float noundef %2, float noundef %3)
  ret void
}

declare dso_local void @sinkf(float noundef, float noundef, float noundef, float noundef) local_unnamed_addr

define dso_local void @testd(double* nocapture noundef readonly %a) local_unnamed_addr #0 {
; RV32I-LABEL: testd:
; RV32I:       # %bb.0: # %entry
; RV32I-NEXT:    lw a7, 4(a0)
; RV32I-NEXT:    lw a6, 0(a0)
; RV32I-NEXT:    lw a5, 20(a0)
; RV32I-NEXT:    lw a4, 16(a0)
; RV32I-NEXT:    lw a3, 28(a0)
; RV32I-NEXT:    lw a2, 24(a0)
; RV32I-NEXT:    lw a1, 12(a0)
; RV32I-NEXT:    lw a0, 8(a0)
; RV32I-NEXT:    tail sinkd
;
; RV32D-LABEL: testd:
; RV32D:       # %bb.0: # %entry
; RV32D-NEXT:    fld fa0, 8(a0)
; RV32D-NEXT:    fld fa1, 24(a0)
; RV32D-NEXT:    fld fa2, 16(a0)
; RV32D-NEXT:    fld fa3, 0(a0)
; RV32D-NEXT:    tail sinkd
;
; RV64I-LABEL: testd:
; RV64I:       # %bb.0: # %entry
; RV64I-NEXT:    ld a3, 0(a0)
; RV64I-NEXT:    ld a2, 16(a0)
; RV64I-NEXT:    ld a1, 24(a0)
; RV64I-NEXT:    ld a0, 8(a0)
; RV64I-NEXT:    tail sinkd
;
; RV64D-LABEL: testd:
; RV64D:       # %bb.0: # %entry
; RV64D-NEXT:    fld fa0, 8(a0)
; RV64D-NEXT:    fld fa1, 24(a0)
; RV64D-NEXT:    fld fa2, 16(a0)
; RV64D-NEXT:    fld fa3, 0(a0)
; RV64D-NEXT:    tail sinkd
;
; RV32I_PAIR-LABEL: testd:
; RV32I_PAIR:       # %bb.0: # %entry
; RV32I_PAIR-NEXT:    lwp a6, a7, 0(a0)
; RV32I_PAIR-NEXT:    lwp a4, a5, 16(a0)
; RV32I_PAIR-NEXT:    lwp a2, a3, 24(a0)
; RV32I_PAIR-NEXT:    lw a1, 12(a0)
; RV32I_PAIR-NEXT:    lw a0, 8(a0)
; RV32I_PAIR-NEXT:    tail sinkd
;
; RV32D_PAIR-LABEL: testd:
; RV32D_PAIR:       # %bb.0: # %entry
; RV32D_PAIR-NEXT:    fld fa0, 8(a0)
; RV32D_PAIR-NEXT:    fld fa2, 16(a0)
; RV32D_PAIR-NEXT:    fld fa1, 24(a0)
; RV32D_PAIR-NEXT:    fld fa3, 0(a0)
; RV32D_PAIR-NEXT:    tail sinkd
;
; RV64I_PAIR-LABEL: testd:
; RV64I_PAIR:       # %bb.0: # %entry
; RV64I_PAIR-NEXT:    ld a3, 0(a0)
; RV64I_PAIR-NEXT:    ld a2, 16(a0)
; RV64I_PAIR-NEXT:    ld a1, 24(a0)
; RV64I_PAIR-NEXT:    ld a0, 8(a0)
; RV64I_PAIR-NEXT:    tail sinkd
;
; RV64I_8500-LABEL: testd:
; RV64I_8500:       # %bb.0: # %entry
; RV64I_8500-NEXT:    fld fa0, 8(a0)
; RV64I_8500-NEXT:    fld fa2, 16(a0)
; RV64I_8500-NEXT:    fld fa1, 24(a0)
; RV64I_8500-NEXT:    fld fa3, 0(a0)
; RV64I_8500-NEXT:    tail sinkd
;
; RV64D_PAIR-LABEL: testd:
; RV64D_PAIR:       # %bb.0: # %entry
; RV64D_PAIR-NEXT:    fld fa0, 8(a0)
; RV64D_PAIR-NEXT:    fld fa2, 16(a0)
; RV64D_PAIR-NEXT:    fld fa1, 24(a0)
; RV64D_PAIR-NEXT:    fld fa3, 0(a0)
; RV64D_PAIR-NEXT:    tail sinkd
;
; RV64D_8500-LABEL: testd:
; RV64D_8500:       # %bb.0: # %entry
; RV64D_8500-NEXT:    fld fa0, 8(a0)
; RV64D_8500-NEXT:    fld fa1, 24(a0)
; RV64D_8500-NEXT:    fld fa2, 16(a0)
; RV64D_8500-NEXT:    fld fa3, 0(a0)
; RV64D_8500-NEXT:    tail sinkd
entry:
  %arrayidx = getelementptr inbounds double, double* %a, i64 1
  %0 = load double, double* %arrayidx, align 8
  %arrayidx1 = getelementptr inbounds double, double* %a, i64 3
  %1 = load double, double* %arrayidx1, align 8
  %arrayidx2 = getelementptr inbounds double, double* %a, i64 2
  %2 = load double, double* %arrayidx2, align 8
  %3 = load double, double* %a, align 8
  tail call void @sinkd(double noundef %0, double noundef %1, double noundef %2, double noundef %3)
  ret void
}

declare dso_local void @sinkd(double noundef, double noundef, double noundef, double noundef) local_unnamed_addr
